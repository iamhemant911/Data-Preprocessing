{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.53392998]\n",
      " [-0.38348249]\n",
      " [ 0.        ]\n",
      " [ 0.38348249]\n",
      " [ 1.53392998]]\n",
      "[[-1.22474487 -1.22474487 -1.22474487]\n",
      " [ 0.          0.          0.        ]\n",
      " [ 1.22474487  1.22474487  1.22474487]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "\n",
    "x=np.array([[-400],[-100],[0],[100],[400]])\n",
    "\n",
    "standardscaler=preprocessing.StandardScaler()\n",
    "x_scaler=standardscaler.fit_transform(x)\n",
    "\n",
    "print(x_scaler)\n",
    "\n",
    "\n",
    "x1=np.array([[1,2,3],[4,5,6],[7,8,9]])\n",
    "standardscaler1=preprocessing.StandardScaler()\n",
    "\n",
    "x_scaler1=standardscaler1.fit_transform(x1)\n",
    "print(x_scaler1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.4472136  0.89442719]\n",
      " [0.37139068 0.92847669]\n",
      " [0.4472136  0.89442719]\n",
      " [0.40613847 0.91381155]\n",
      " [0.52999894 0.8479983 ]]\n",
      "[[0.26726124 0.53452248 0.80178373]\n",
      " [0.45584231 0.56980288 0.68376346]\n",
      " [0.50257071 0.57436653 0.64616234]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "\n",
    "x=np.array([[1,2],[2,5],[3,6],[4,9],[5,8]])\n",
    "\n",
    "normalizer=preprocessing.Normalizer()\n",
    "normal=normalizer.fit_transform(x)\n",
    "\n",
    "print(normal)\n",
    "\n",
    "\n",
    "x1=np.array([[1,2,3],[4,5,6],[7,8,9]])\n",
    "normalizer1=preprocessing.Normalizer()\n",
    "\n",
    "normal1=normalizer1.fit_transform(x1)\n",
    "print(normal1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [1 1]]\n",
      "[[0 0 0]\n",
      " [0 0 1]\n",
      " [1 1 1]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "\n",
    "x=np.array([[1,2],[2,5],[3,6],[4,9],[5,8]])\n",
    "\n",
    "binarizer=preprocessing.Binarizer(4)\n",
    "binarizer_scaled=binarizer.fit_transform(x)\n",
    "\n",
    "print(binarizer_scaled)\n",
    "\n",
    "\n",
    "x1=np.array([[1,2,3],[4,5,6],[7,8,9]])\n",
    "binarizer1=preprocessing.Binarizer(5)\n",
    "\n",
    "binarizer_scaled1=binarizer1.fit_transform(x1)\n",
    "print(binarizer_scaled1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Robust Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lower Quartile: -100.0\n",
      "Medium: 0.0\n",
      "Upper Quartile: 100.0\n",
      "[[-2.5]\n",
      " [-0.5]\n",
      " [ 0. ]\n",
      " [ 0.5]\n",
      " [ 4.5]]\n",
      "[[-0.8 -1.  -1. ]\n",
      " [ 0.   0.   0. ]\n",
      " [ 1.2  1.   1. ]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "x=np.array([[-500],[-100],[0],[100],[900]])\n",
    "robust=preprocessing.RobustScaler()\n",
    "x_robust=robust.fit_transform(x)\n",
    "\n",
    "Q1=np.percentile(x,25)\n",
    "Q2=np.percentile(x,50)\n",
    "Q3=np.percentile(x,75)\n",
    "\n",
    "print('Lower Quartile:',Q1)\n",
    "print('Medium:',Q2)\n",
    "print('Upper Quartile:',Q3)\n",
    "\n",
    "robust_scaler1=(x-Q2)/(Q3-Q1)\n",
    "print(robust_scaler1)\n",
    "#####################################################################\n",
    "\n",
    "\n",
    "x1=np.array([[2,2,3],[4,5,6],[7,8,9]])\n",
    "robust_scaler2=robust.fit_transform(x1)\n",
    "print(robust_scaler2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MaxAbs Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.55555556]\n",
      " [-0.11111111]\n",
      " [ 0.        ]\n",
      " [ 0.11111111]\n",
      " [ 1.        ]]\n",
      "[[ 0.14285714  0.25        0.33333333]\n",
      " [-0.57142857  0.625      -0.66666667]\n",
      " [ 1.         -1.          1.        ]]\n",
      "          0         1         2         3         4\n",
      "0  1.067854  1.962566  1.353087  0.121282 -1.101811\n",
      "1  0.347087 -1.136351  0.197415  1.017082 -0.799175\n",
      "2  0.835230  1.404004  0.586439 -0.062601 -0.560789\n",
      "3 -0.704364 -0.357857 -0.445355 -0.453031  0.577577\n",
      "[[ 1.          1.          1.          0.11924533 -1.        ]\n",
      " [ 0.32503236 -0.57901291  0.14589987  1.         -0.72532861]\n",
      " [ 0.78215786  0.71539196  0.43340799 -0.06154979 -0.50896978]\n",
      " [-0.65960731 -0.1823414  -0.32913949 -0.44542254  0.52420722]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "\n",
    "x=np.array([[-500.5],[-100.1],[0],[100.1],[900.9]])\n",
    "\n",
    "maxabs=preprocessing.MaxAbsScaler()\n",
    "x_scaled=maxabs.fit_transform(x)\n",
    "\n",
    "print(x_scaled)\n",
    "\n",
    "x1=np.array([[1,2,3],[-4,5,-6],[7,-8,9]])\n",
    "\n",
    "x_scaled2=maxabs.fit_transform(x1)\n",
    "\n",
    "print(x_scaled2)\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df=pd.DataFrame(np.random.randn(4,5),columns=np.arange(5))\n",
    "print(df)\n",
    "\n",
    "x_scaled3=maxabs.fit_transform(df)\n",
    "print(x_scaled3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MinMax Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.   ]\n",
      " [0.375]\n",
      " [0.5  ]\n",
      " [0.625]\n",
      " [1.   ]]\n",
      "[[0.  0.  0. ]\n",
      " [0.5 0.5 0.5]\n",
      " [1.  1.  1. ]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "\n",
    "x=np.array([[-400],[-100],[0],[100],[400]])\n",
    "\n",
    "minmaxscaler=preprocessing.MinMaxScaler(feature_range=(0,1))\n",
    "x_scaler=minmaxscaler.fit_transform(x)\n",
    "\n",
    "print(x_scaler)\n",
    "\n",
    "\n",
    "x1=np.array([[1,2,3],[4,5,6],[7,8,9]])\n",
    "minmaxscaler1=preprocessing.MinMaxScaler(feature_range=(0,1))\n",
    "\n",
    "x_scaler1=minmaxscaler1.fit_transform(x1)\n",
    "print(x_scaler1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inversed Transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.53392998]\n",
      " [-0.38348249]\n",
      " [ 0.        ]\n",
      " [ 0.38348249]\n",
      " [ 1.53392998]]\n",
      "[[-400.]\n",
      " [-100.]\n",
      " [   0.]\n",
      " [ 100.]\n",
      " [ 400.]]\n",
      "[[0.   ]\n",
      " [0.375]\n",
      " [0.5  ]\n",
      " [0.625]\n",
      " [1.   ]]\n",
      "[[-400.]\n",
      " [-100.]\n",
      " [   0.]\n",
      " [ 100.]\n",
      " [ 400.]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "\n",
    "x=np.array([[-400],[-100],[0],[100],[400]])\n",
    "\n",
    "standardscaler=preprocessing.StandardScaler()\n",
    "x_scaler=standardscaler.fit_transform(x)\n",
    "\n",
    "print(x_scaler)\n",
    "x_scaledback=standardscaler.inverse_transform(x_scaler)\n",
    "print(x_scaledback)\n",
    "\n",
    "\n",
    "##############################################\n",
    "\n",
    "x=np.array([[-400],[-100],[0],[100],[400]])\n",
    "\n",
    "minmaxscaler=preprocessing.MinMaxScaler(feature_range=(0,1))\n",
    "x_scaler=minmaxscaler.fit_transform(x)\n",
    "\n",
    "print(x_scaler)\n",
    "x_minmax_scaleback=minmaxscaler.inverse_transform(x_scaler)\n",
    "print(x_minmax_scaleback)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
